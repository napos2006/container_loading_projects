{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/napos2006/container_loading_projects/blob/main/pandas_acceleration_with_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_63kkzYSrX1"
      },
      "source": [
        "# Accelerating pandas with GPU: Sort the count of rows grouped on columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igTJBL0vUb4F"
      },
      "source": [
        "Add `%load_ext cudf.pandas` before importing pandas to speed up operations using GPU\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fuXnmHmSBzq"
      },
      "outputs": [],
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Define the species categories\n",
        "species_categories = ['setosa', 'versicolor', 'virginica']\n",
        "flower_color_categories = ['red','yellow','green']\n",
        "\n",
        "# Define the range for each attribute based on typical iris flower measurements\n",
        "sepal_length_range = (4.0, 8.0)\n",
        "\n",
        "# Create data for 1,000,000 samples\n",
        "n = 1000000\n",
        "data = {\n",
        "    'sepal_length': [random.uniform(*sepal_length_range) for _ in range(n)],\n",
        "    'flower_color': [random.choice(flower_color_categories) for _ in range(n)],\n",
        "    'species': [random.choice(species_categories) for _ in range(n)]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.groupby(['species','flower_color']).size().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2DVoM7ifOAq"
      },
      "source": [
        "# Acceleration pandas with GPU: Merging / Joining dataframes-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6MWgjQRfZl-"
      },
      "source": [
        "Add `%load_ext cudf.pandas` before importing pandas to speed up operations using GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW3bxTL3f5Pd"
      },
      "outputs": [],
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the number of rows\n",
        "num_rows = 1000000\n",
        "\n",
        "states = [\"NY\", \"NJ\", \"CA\", \"TX\"]\n",
        "violations = [\"Double Parking\", \"Expired Meter\", \"No Parking\", \"Fire Hydrant\",\n",
        "              \"Bus Stop\"]\n",
        "vehicle_types = [\"SUBN\", \"SDN\"]\n",
        "\n",
        "# Generate random data for Dataset 1\n",
        "data1 = {\n",
        "    \"Registration State\": np.random.choice(states, size=num_rows),\n",
        "    \"Ticket Number\": np.random.randint(1000000000, 9999999999, size=num_rows)\n",
        "}\n",
        "\n",
        "# Generate random data for Dataset 2\n",
        "data2 = {\n",
        "    \"Ticket Number\": np.random.choice(data1['Ticket Number'], size=num_rows),  # Reusing ticket numbers to ensure matches\n",
        "    \"Violation Description\": np.random.choice(violations, size=num_rows)\n",
        "}\n",
        "\n",
        "# Create DataFrames\n",
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Perform an inner join on 'Ticket Number'\n",
        "merged_df = pd.merge(df1, df2, on=\"Ticket Number\", how=\"inner\")\n",
        "\n",
        "# Display some of the joined data\n",
        "print(merged_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41DVaHZHS571"
      },
      "source": [
        "# Accelerating pandas with GPU: Groupby aggregate on timeseries data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YDBGAMOWZoG"
      },
      "source": [
        "Add `%load_ext cudf.pandas` before importing pandas to speed up operations using GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlhe0827S1J5"
      },
      "outputs": [],
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the number of rows\n",
        "num_rows = 1000000\n",
        "\n",
        "# Define the possible values\n",
        "states = [\"NY\", \"NJ\", \"CA\", \"TX\"]\n",
        "violations = [\"Double Parking\", \"Expired Meter\", \"No Parking\", \"Fire Hydrant\", \"Bus Stop\"]\n",
        "vehicle_types = [\"SUBN\", \"SDN\"]\n",
        "\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "# Create a date range\n",
        "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "# Generate random data\n",
        "data = {\n",
        "    \"Registration State\": np.random.choice(states, size=num_rows),\n",
        "    \"Violation Description\": np.random.choice(violations, size=num_rows),\n",
        "    \"Vehicle Body Type\": np.random.choice(vehicle_types, size=num_rows),\n",
        "    \"Issue Date\": np.random.choice(dates, size=num_rows),\n",
        "    \"Ticket Number\": np.random.randint(1000000000, 9999999999, size=num_rows)\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Adding issue weekday based on the \"Issue Date\"\n",
        "weekday_names = {\n",
        "    0: \"Monday\",\n",
        "    1: \"Tuesday\",\n",
        "    2: \"Wednesday\",\n",
        "    3: \"Thursday\",\n",
        "    4: \"Friday\",\n",
        "    5: \"Saturday\",\n",
        "    6: \"Sunday\",\n",
        "}\n",
        "\n",
        "df[\"issue_weekday\"] = df[\"Issue Date\"].dt.weekday.map(weekday_names)\n",
        "\n",
        "# Grouping by issue_weekday and counting the Summons Number\n",
        "df.groupby([\"Issue Date\"])[\"Ticket Number\"\n",
        "].count().sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr4Niz4tWmCW"
      },
      "source": [
        "# Accelerating pandas with GPU: Count of values and GroupBy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_OzcTpBezh9"
      },
      "source": [
        "Add `%load_ext cudf.pandas` before importing pandas to speed up operations using GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYWROytuURFH"
      },
      "outputs": [],
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Randomly generated dataset of parking violations-\n",
        "# Define the number of rows\n",
        "num_rows = 1000000\n",
        "\n",
        "states = [\"NY\", \"NJ\", \"CA\", \"TX\"]\n",
        "violations = [\"Double Parking\", \"Expired Meter\", \"No Parking\",\n",
        "              \"Fire Hydrant\", \"Bus Stop\"]\n",
        "vehicle_types = [\"SUBN\", \"SDN\"]\n",
        "\n",
        "# Create a date range\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "# Generate random data\n",
        "data = {\n",
        "    \"Registration State\": np.random.choice(states, size=num_rows),\n",
        "    \"Violation Description\": np.random.choice(violations, size=num_rows),\n",
        "    \"Vehicle Body Type\": np.random.choice(vehicle_types, size=num_rows),\n",
        "    \"Issue Date\": np.random.choice(dates, size=num_rows),\n",
        "    \"Ticket Number\": np.random.randint(1000000000, 9999999999, size=num_rows)\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Which parking violation is most commonly committed by vehicles from various U.S states?\n",
        "\n",
        "(df[[\"Registration State\", \"Violation Description\"]]  # get only these two columns\n",
        " .value_counts()  # get the count of offences per state and per type of offence\n",
        " .groupby(\"Registration State\")  # group by state\n",
        " .head(1)  # get the first row in each group (the type of offence with the largest count)\n",
        " .sort_index()  # sort by state name\n",
        " .reset_index()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sWzpEvabvBW"
      },
      "source": [
        "# Accelerating pandas with GPU: Rolling Window Average\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbKJGeVnb6Uj"
      },
      "outputs": [],
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Randomly generated dataset of parking violations-\n",
        "# Define the number of rows\n",
        "num_rows = 1000000\n",
        "\n",
        "states = [\"NY\", \"NJ\", \"CA\", \"TX\"]\n",
        "violations = [\"Double Parking\", \"Expired Meter\", \"No Parking\",\n",
        "              \"Fire Hydrant\", \"Bus Stop\"]\n",
        "vehicle_types = [\"SUBN\", \"SDN\"]\n",
        "\n",
        "# Create a date range\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "# Generate random data\n",
        "data = {\n",
        "    \"Registration State\": np.random.choice(states, size=num_rows),\n",
        "    \"Violation Description\": np.random.choice(violations, size=num_rows),\n",
        "    \"Vehicle Body Type\": np.random.choice(vehicle_types, size=num_rows),\n",
        "    \"Issue Date\": np.random.choice(dates, size=num_rows),\n",
        "    \"Ticket Number\": np.random.randint(1000000000, 9999999999, size=num_rows)\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# How does the parking violations change from day to day segmented by vehicle type\n",
        "# Averaged using a 7-day rolling mean\n",
        "\n",
        "daily_counts = df.groupby(['Issue Date', 'Vehicle Body Type']\n",
        "                          ).size().unstack(fill_value=0)\n",
        "\n",
        "# Calculate a 7-day rolling mean of daily violations for each vehicle type\n",
        "rolling_means = daily_counts.rolling(window=7).mean()\n",
        "\n",
        "# Display the rolling means for each vehicle type over time\n",
        "rolling_means.tail(100).plot(figsize=(14, 7),\n",
        "                             title=\"7-Day Rolling Average of Parking Violations by Vehicle Type\")\n",
        "plt.ylabel(\"Average Number of Violations\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}